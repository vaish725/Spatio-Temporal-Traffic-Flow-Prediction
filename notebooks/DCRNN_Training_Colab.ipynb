{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b97591",
   "metadata": {},
   "source": [
    "# üöó DCRNN Traffic Flow Prediction - Google Colab Edition\n",
    "\n",
    "**Project**: Spatio-Temporal Traffic Flow Prediction  \n",
    "**Author**: Vaishnavi Kamdi  \n",
    "**Course**: Advanced ML, Fall 2025, GWU  \n",
    "\n",
    "---\n",
    "\n",
    "## üìã What This Notebook Does\n",
    "\n",
    "1. ‚úÖ Clones your GitHub repository\n",
    "2. ‚úÖ Installs all dependencies\n",
    "3. ‚úÖ Enables GPU acceleration (T4/P100/V100)\n",
    "4. ‚úÖ Trains DCRNN model (10-30x faster than CPU)\n",
    "5. ‚úÖ Evaluates on test set\n",
    "6. ‚úÖ Generates visualizations\n",
    "7. ‚úÖ Downloads results to your local machine\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Quick Start\n",
    "\n",
    "**Before running**:\n",
    "1. Go to `Runtime` ‚Üí `Change runtime type` ‚Üí Set `Hardware accelerator` to **GPU**\n",
    "2. Click `Runtime` ‚Üí `Run all` (or run cells sequentially)\n",
    "\n",
    "**Expected time**: ~10-15 minutes on GPU (vs 2-4 hours on CPU!)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc4ca43",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup: Clone Repository & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0087385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your GitHub repository (will get latest version with fixes)\n",
    "!git clone https://github.com/vaish725/Spatio-Temporal-Traffic-Flow-Prediction.git\n",
    "%cd Spatio-Temporal-Traffic-Flow-Prediction\n",
    "\n",
    "# Ensure we have the latest code\n",
    "!git pull origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385ed4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: No GPU detected. Go to Runtime ‚Üí Change runtime type ‚Üí Select GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb18d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch-geometric\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548898dd",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Verify Installation & Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb68aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify project structure\n",
    "import os\n",
    "\n",
    "required_files = [\n",
    "    'models/dcrnn.py',\n",
    "    'models/diffusion_conv.py',\n",
    "    'src/dataset.py',\n",
    "    'src/metrics.py',\n",
    "    'scripts/train.py',\n",
    "    'scripts/evaluate.py',\n",
    "    'traffic_flow_setup.py'\n",
    "]\n",
    "\n",
    "print(\"üìÅ Checking project structure...\")\n",
    "all_exist = True\n",
    "for file in required_files:\n",
    "    exists = os.path.exists(file)\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"{status} {file}\")\n",
    "    if not exists:\n",
    "        all_exist = False\n",
    "\n",
    "if all_exist:\n",
    "    print(\"\\n‚úÖ All files present! Ready to train.\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Some files missing. Check your repository.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77003c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports\n",
    "print(\"üîç Testing imports...\")\n",
    "try:\n",
    "    from models.dcrnn import DCRNN\n",
    "    from models.diffusion_conv import DiffusionConv\n",
    "    from src.dataset import TrafficDataset, create_dataloaders\n",
    "    from src.metrics import masked_mae, masked_rmse, masked_mape\n",
    "    print(\"‚úÖ All imports successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Import error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e19648e",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Train DCRNN Model (GPU-Accelerated)\n",
    "\n",
    "This will train your model with:\n",
    "- **GPU acceleration** (10-30x faster)\n",
    "- **Early stopping** (patience=15)\n",
    "- **Model checkpointing** (best & final models)\n",
    "- **Progress tracking** with tqdm\n",
    "\n",
    "**Expected time on GPU**: 10-20 minutes (vs 2-4 hours on CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420a06c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "!python3 scripts/train.py \\\n",
    "  --epochs 100 \\\n",
    "  --batch_size 64 \\\n",
    "  --hidden_dim 64 \\\n",
    "  --num_layers 2 \\\n",
    "  --lr 0.001 \\\n",
    "  --patience 15 \\\n",
    "  --checkpoint_dir checkpoints \\\n",
    "  --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a1913",
   "metadata": {},
   "source": [
    "### üìä Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a32727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training history\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('checkpoints/training_history.json', 'r') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "print(\"üéØ Training Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total epochs trained: {len(history)}\")\n",
    "print(f\"Best validation loss: {min([h['val_loss'] for h in history]):.4f}\")\n",
    "print(f\"Best epoch: {min(history, key=lambda x: x['val_loss'])['epoch']}\")\n",
    "print(f\"Training time: {sum([h['epoch_time'] for h in history]) / 60:.2f} minutes\")\n",
    "\n",
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot([h['epoch'] for h in history], [h['train_loss'] for h in history], label='Train Loss', marker='o')\n",
    "axes[0].plot([h['epoch'] for h in history], [h['val_loss'] for h in history], label='Val Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training & Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# MAE curves\n",
    "axes[1].plot([h['epoch'] for h in history], [h['val_mae'] for h in history], label='Val MAE', marker='o', color='green')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_title('Validation MAE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Training curves saved as 'training_curves.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290814cc",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Evaluate Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c60fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "!python3 scripts/evaluate.py \\\n",
    "  --checkpoint checkpoints/best_model.pt \\\n",
    "  --hidden_dim 64 \\\n",
    "  --num_layers 2 \\\n",
    "  --plot \\\n",
    "  --save_predictions \\\n",
    "  --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b387c03",
   "metadata": {},
   "source": [
    "### üìà Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac185394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display evaluation metrics\n",
    "import json\n",
    "\n",
    "with open('results/metrics.json', 'r') as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "print(\"üéØ Test Set Performance\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Overall MAE:  {metrics['overall']['mae']:.4f}\")\n",
    "print(f\"Overall RMSE: {metrics['overall']['rmse']:.4f}\")\n",
    "print(f\"Overall MAPE: {metrics['overall']['mape']:.2f}%\")\n",
    "print()\n",
    "print(\"Multi-Horizon Performance:\")\n",
    "print(\"-\" * 60)\n",
    "for horizon, vals in metrics['horizons'].items():\n",
    "    print(f\"{horizon:12s} ‚Üí MAE: {vals['mae']:.4f}, RMSE: {vals['rmse']:.4f}, MAPE: {vals['mape']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0c484e",
   "metadata": {},
   "source": [
    "### üìä Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fbb9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display generated plots\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"üìà Sample Predictions:\")\n",
    "display(Image('results/predictions.png'))\n",
    "\n",
    "print(\"\\nüìä Horizon-wise Performance:\")\n",
    "display(Image('results/horizon_metrics.png'))\n",
    "\n",
    "print(\"\\nüìà Training Curves:\")\n",
    "display(Image('training_curves.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3fa014",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Download Results to Local Machine\n",
    "\n",
    "This will create a ZIP file with all your results that you can download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b84006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ZIP with all results\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "zip_name = f'dcrnn_results_{timestamp}'\n",
    "\n",
    "# Create results archive\n",
    "!mkdir -p results_archive\n",
    "!cp -r checkpoints results_archive/\n",
    "!cp -r results results_archive/\n",
    "!cp training_curves.png results_archive/\n",
    "\n",
    "# Create ZIP\n",
    "shutil.make_archive(zip_name, 'zip', 'results_archive')\n",
    "\n",
    "print(f\"‚úÖ Results packaged as: {zip_name}.zip\")\n",
    "print(f\"üì¶ Size: {os.path.getsize(f'{zip_name}.zip') / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882a04c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the ZIP file\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üì• Downloading results...\")\n",
    "files.download(f'{zip_name}.zip')\n",
    "print(\"‚úÖ Download complete! Check your browser's downloads folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf25268",
   "metadata": {},
   "source": [
    "## üîß Optional: Advanced Configurations\n",
    "\n",
    "Try different hyperparameters for better performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948cea95",
   "metadata": {},
   "source": [
    "### Configuration 1: Larger Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc681658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with larger hidden dimension\n",
    "!python3 scripts/train.py \\\n",
    "  --epochs 100 \\\n",
    "  --batch_size 32 \\\n",
    "  --hidden_dim 128 \\\n",
    "  --num_layers 3 \\\n",
    "  --lr 0.001 \\\n",
    "  --patience 15 \\\n",
    "  --checkpoint_dir checkpoints_large \\\n",
    "  --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a135d2fa",
   "metadata": {},
   "source": [
    "### Configuration 2: Learning Rate Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d23462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with learning rate decay\n",
    "!python3 scripts/train.py \\\n",
    "  --epochs 100 \\\n",
    "  --batch_size 64 \\\n",
    "  --hidden_dim 64 \\\n",
    "  --num_layers 2 \\\n",
    "  --lr 0.001 \\\n",
    "  --lr_decay \\\n",
    "  --lr_decay_rate 0.5 \\\n",
    "  --patience 20 \\\n",
    "  --checkpoint_dir checkpoints_lr_decay \\\n",
    "  --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d15023",
   "metadata": {},
   "source": [
    "### Configuration 3: More Diffusion Hops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1097578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with more diffusion steps\n",
    "!python3 scripts/train.py \\\n",
    "  --epochs 100 \\\n",
    "  --batch_size 64 \\\n",
    "  --hidden_dim 64 \\\n",
    "  --num_layers 2 \\\n",
    "  --max_diffusion_step 3 \\\n",
    "  --lr 0.001 \\\n",
    "  --patience 15 \\\n",
    "  --checkpoint_dir checkpoints_diffusion3 \\\n",
    "  --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa77794",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Notes\n",
    "\n",
    "### GPU vs CPU Performance\n",
    "- **CPU (local)**: 2-4 hours for 100 epochs\n",
    "- **GPU (Colab)**: 10-20 minutes for 100 epochs\n",
    "- **Speedup**: ~10-30x faster!\n",
    "\n",
    "### Colab GPU Options\n",
    "- **Free tier**: T4 GPU (16GB) - plenty for this project\n",
    "- **Colab Pro**: V100/A100 (even faster)\n",
    "\n",
    "### Tips\n",
    "1. **Save frequently**: Colab sessions disconnect after 12 hours\n",
    "2. **Mount Google Drive**: Store results automatically\n",
    "3. **Use checkpoints**: Resume training if disconnected\n",
    "4. **Download results**: Don't lose your trained models!\n",
    "\n",
    "### Troubleshooting\n",
    "- **No GPU**: Go to `Runtime` ‚Üí `Change runtime type` ‚Üí Select `GPU`\n",
    "- **Disconnected**: Re-run all cells from the top\n",
    "- **Out of memory**: Reduce `batch_size` or `hidden_dim`\n",
    "- **Import errors**: Make sure repository is cloned correctly\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Done!\n",
    "\n",
    "Your DCRNN model is now trained on GPU! üöÄ\n",
    "\n",
    "**What's in your ZIP file**:\n",
    "- `checkpoints/` - Trained models (best & final)\n",
    "- `results/` - Metrics and visualizations\n",
    "- `training_curves.png` - Training history plot\n",
    "\n",
    "**Next steps**:\n",
    "1. Extract the ZIP file on your local machine\n",
    "2. Use results in your report/presentation\n",
    "3. Compare with your CPU training results\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
