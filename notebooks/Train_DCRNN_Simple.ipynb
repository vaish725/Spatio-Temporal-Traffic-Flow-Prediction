{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09a9321a",
   "metadata": {},
   "source": [
    "# DCRNN Traffic Prediction - Simple Training\n",
    "\n",
    "**Just run all cells in order. That's it.**\n",
    "\n",
    "Expected time: **10-15 minutes** on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d86c25",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ef661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!rm -rf Spatio-Temporal-Traffic-Flow-Prediction\n",
    "!git clone https://github.com/vaish725/Spatio-Temporal-Traffic-Flow-Prediction.git\n",
    "%cd Spatio-Temporal-Traffic-Flow-Prediction\n",
    "!git pull origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4357e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch-geometric tqdm matplotlib scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ebcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"⚠️ No GPU - Training will be slow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a698f0",
   "metadata": {},
   "source": [
    "## Step 2: Get Data\n",
    "\n",
    "**First time only**: Run cells below to download and preprocess data (takes ~5 min)\n",
    "\n",
    "**Already have data?** Skip to Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3230e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data exists\n",
    "import os\n",
    "if os.path.exists('data/pems_bay_processed.npz'):\n",
    "    print(\"✅ Data already exists! Skip to Step 3\")\n",
    "else:\n",
    "    print(\"❌ Need to download and preprocess data\")\n",
    "    print(\"   Run the next 4 cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f5ca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download PEMS-BAY dataset (82MB)\n",
    "!mkdir -p data\n",
    "!wget -q -O data/PEMS-BAY.csv \"https://zenodo.org/record/5724362/files/PEMS-BAY.csv\"\n",
    "print(f\"Downloaded: {os.path.getsize('data/PEMS-BAY.csv')/1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7543ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Loading and preprocessing data...\")\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv('data/PEMS-BAY.csv')\n",
    "speed_data = df.drop(columns=[df.columns[0]]).values.astype(np.float32)\n",
    "print(f\"Shape: {speed_data.shape} (timesteps x sensors)\")\n",
    "\n",
    "# Handle missing values\n",
    "for i in range(speed_data.shape[1]):\n",
    "    mask = np.isnan(speed_data[:, i])\n",
    "    if mask.any():\n",
    "        speed_data[mask, i] = np.interp(\n",
    "            np.flatnonzero(mask),\n",
    "            np.flatnonzero(~mask),\n",
    "            speed_data[~mask, i]\n",
    "        )\n",
    "\n",
    "# Normalize\n",
    "mean = speed_data.mean()\n",
    "std = speed_data.std()\n",
    "speed_data_norm = (speed_data - mean) / std\n",
    "print(f\"Mean: {mean:.2f} mph, Std: {std:.2f} mph\")\n",
    "\n",
    "# Create sequences\n",
    "T_in, T_out = 12, 12\n",
    "num_samples = speed_data_norm.shape[0] - T_in - T_out + 1\n",
    "num_nodes = speed_data_norm.shape[1]\n",
    "\n",
    "X = np.zeros((num_samples, T_in, num_nodes, 1), dtype=np.float32)\n",
    "y = np.zeros((num_samples, T_out, num_nodes, 1), dtype=np.float32)\n",
    "\n",
    "for i in tqdm(range(num_samples), desc=\"Creating sequences\"):\n",
    "    X[i, :, :, 0] = speed_data_norm[i:i+T_in, :]\n",
    "    y[i, :, :, 0] = speed_data_norm[i+T_in:i+T_in+T_out, :]\n",
    "\n",
    "# Split data\n",
    "train_split = int(0.7 * num_samples)\n",
    "val_split = int(0.8 * num_samples)\n",
    "\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_val, y_val = X[train_split:val_split], y[train_split:val_split]\n",
    "X_test, y_test = X[val_split:], y[val_split:]\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbdad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adjacency matrix\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "print(\"Creating adjacency matrix...\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate sensor positions\n",
    "positions = np.linspace(0, 100, num_nodes).reshape(-1, 1)\n",
    "positions = np.hstack([positions, np.random.randn(num_nodes, 1) * 5])\n",
    "\n",
    "# Gaussian kernel\n",
    "distances = cdist(positions, positions, metric='euclidean')\n",
    "sigma = np.std(distances) * 0.1\n",
    "adj_matrix = np.exp(-distances**2 / (sigma**2))\n",
    "adj_matrix[adj_matrix < 0.1] = 0\n",
    "np.fill_diagonal(adj_matrix, 1.0)\n",
    "\n",
    "# Transition matrices\n",
    "row_sum = adj_matrix.sum(axis=1, keepdims=True) + 1e-8\n",
    "P_fwd = (adj_matrix / row_sum).astype(np.float32)\n",
    "\n",
    "col_sum = adj_matrix.sum(axis=0, keepdims=True) + 1e-8\n",
    "P_bwd = (adj_matrix / col_sum).T.astype(np.float32)\n",
    "\n",
    "print(f\"Nodes: {num_nodes}, Edges: {int((adj_matrix > 0).sum() - num_nodes) / 2}\")\n",
    "\n",
    "# Save everything\n",
    "np.savez_compressed(\n",
    "    'data/pems_bay_processed.npz',\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_val=X_val, y_val=y_val,\n",
    "    X_test=X_test, y_test=y_test,\n",
    "    P_fwd=P_fwd, P_bwd=P_bwd,\n",
    "    mean=mean, std=std,\n",
    "    adj_matrix=adj_matrix\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Data saved: {os.path.getsize('data/pems_bay_processed.npz')/1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741eeff7",
   "metadata": {},
   "source": [
    "## Step 3: Train Model\n",
    "\n",
    "**This is the only cell you need if data already exists!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 scripts/train_colab_safe.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4c3e4d",
   "metadata": {},
   "source": [
    "## Step 4: Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display training history\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('checkpoints_colab/history.json', 'r') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "epochs = history['epoch']\n",
    "val_mae = history['val_mae']\n",
    "\n",
    "print(\"Training Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Best MAE: {min(val_mae):.3f} mph\")\n",
    "print(f\"Baseline MAE: 7.997 mph\")\n",
    "print(f\"Improvement: {(7.997 - min(val_mae)) / 7.997 * 100:.1f}%\")\n",
    "print(f\"DCRNN Paper (SOTA): 1.38 mph\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(epochs, val_mae, marker='o', color='green', linewidth=2)\n",
    "plt.axhline(min(val_mae), color='red', linestyle='--', alpha=0.5, label=f'Best: {min(val_mae):.3f}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation MAE (mph)')\n",
    "plt.title('Training Progress')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "if min(val_mae) < 5.0:\n",
    "    print(\"\\n✅ SUCCESS! Model is learning patterns!\")\n",
    "else:\n",
    "    print(\"\\n⚠️ MAE still high. Try training longer or with more data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fa1a44",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "Your model is saved in `checkpoints_colab/best_model.pt`\n",
    "\n",
    "**To evaluate on test set:**\n",
    "```python\n",
    "!python3 scripts/evaluate.py --checkpoint checkpoints_colab/best_model.pt --hidden_dim 64 --num_layers 2\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
